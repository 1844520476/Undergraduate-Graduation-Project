{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 自动标注\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关综述\n",
    "1.[Automatic image annotation and retrieval using cross-media relevance models(2003.07)](https://dl.acm.org/doi/abs/10.1145/860435.860459)\n",
    "使用跨媒体关联模型的自动图像标注和检索\n",
    "\n",
    "2.[A review on automatic image annotation techniques(2012.01)](https://www.sciencedirect.com/science/article/pii/S0031320311002391)\n",
    "\n",
    "3.[A survey and analysis on automatic image annotation(2018.07)](https://www.sciencedirect.com/science/article/pii/S0031320318300670)\n",
    "\n",
    "4.[半监督深度学习图像分类方法研究综述(2021.03)](http://fcst.ceaj.org/CN/abstract/abstract2718.shtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer学习顺序应如下：\n",
    "1.MLP\n",
    "[深度理解多层感知机（MLP）](https://cleverbobo.github.io/2020/08/30/bp/)\n",
    "\n",
    "2.RNN\n",
    "[一文搞懂RNN（循环神经网络）基础篇](https://zhuanlan.zhihu.com/p/30844905)\n",
    "\n",
    "3.seq2seq/编码器解码器架构\n",
    "[Encoder-Decoder 和 Seq2Seq](https://easyai.tech/ai-definition/encoder-decoder-seq2seq/)\n",
    "\n",
    "4.注意力机制&自注意力\n",
    "[Attention注意力机制的理解](https://cloud.tencent.com/developer/article/1489033)\n",
    "\n",
    "[什么是自注意力机制](https://www.jiqizhixin.com/articles/100902)\n",
    "\n",
    "5.transformer\n",
    "[Transformer论文逐段精读【论文精读】](https://www.bilibili.com/video/BV1pu411o7BE)\n",
    "\n",
    "[A Survey of Transformers](https://arxiv.org/pdf/2106.04554.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对Clip模型的拓展\n",
    "\n",
    "1.1[本人github项目地址](https://github.com/1844520476/NTViT)\n",
    "\n",
    "1.2[本人博客](https://blog.csdn.net/qq_44942172/article/details/123141591?utm_source=app&app_version=5.0.0&utm_source=app)\n",
    "\n",
    "2.1[原始论文CLIP:Connecting Text and Images](https://openai.com/blog/clip/)\n",
    "\n",
    "2.2[原始代码openai/CLIP: Contrastive Language-Image Pretraining](https://github.com/openai/CLIP)\n",
    "\n",
    "3.LAION-400M数据集\n",
    "\n",
    "[LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs](https://arxiv.org/abs/2111.02114)\n",
    "\n",
    "\n",
    "4.VLP综述VLP:\n",
    "\n",
    "[A Survey on Vision-Language Pre-training](https://arxiv.org/abs/2202.09061)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、论文\n",
    "\n",
    "在本节中，我们将聚焦于:*自动标注*（automatic annotation）。如所示，以下为自动标注领域相关论文："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 39,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "### 1.Match系列\n",
    "近来半监督图像分类任务有两大核心方法：一致性正则（Consistency Regularization）和打伪标签法（Pseudo-Label）。当前SOTA水平的半监督算法，通常是这两种方法的结合产物，比如知名的Match系列方法：MixMatch（NIPS 2019），ReMixMatch（ICLR 2020），FixMatch（NIPS 2020）和FeatMatch（ECCV 2020）。\n",
    "\n",
    "ps.[伪标签介绍](http://www.atyun.com/8381.html)\n",
    "\n",
    "### Matchx系列论文\n",
    "* [FixMatch：只用10张标注图片训练CIFAR10](https://aijishu.com/a/1060000000104728)\n",
    "\n",
    "* [Flexmatch(Fixmatch进阶版)介绍](https://zhuanlan.zhihu.com/p/430387494)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于自然语言监督信号下的迁移视觉网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Clip\n",
    "CLIP(Contrastive Language-Image Pre-Training对比语言-图像预训练)是一种针对各种(图像、文本)对进行训练的神经网络。它可以使用自然语言来预测最相关的文本片段，给出一张图片，而不是直接对任务进行优化，类似于GPT-2和gpt-3的zero-shot能力。CLIP与原始ResNet50在ImageNet数据集zero-shot上的性能匹敌，没有使用任何原始的1.28M张带标记的图片示例，克服了计算机视觉中的几个主要挑战。\n",
    "\n",
    "[OpenAI官网有关Clip的论文](https://openai.com/blog/clip/)\n",
    "\n",
    "[知乎相关讨论](https://www.zhihu.com/question/438649654)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.自适应的 Web 图像语义自动标注方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先利用 Web 标签资源自动获取训练数据;然后通过带约束的分段惩罚加权回归模型将关联文本\n",
    "权重分布自适应学习和先验知识约束有机地结合在一起,实现 Web 图像语义的自动标注。\n",
    "\n",
    "[论文地址](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.710.1673&rep=rep1&type=pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## “主动学习”：如何显著地减少标注代价\n",
    "主动学习（ActiveLearning，AL）是一种挑选具有高信息度数据的有效方式，它将数据标注过程呈现为学习算法和用户之间的交互。其中，算法负责挑选对训练 AI 模型价值更高的样本，而用户则标注那些挑选出来的样本。\n",
    "\n",
    "随机选择（random select）→策略选择（strategy select）\n",
    "\n",
    "思考中等难度选择→模拟退火选择\n",
    "\n",
    "[博客地址](https://blog.csdn.net/Houchaoqun_XMU/article/details/80146710)\n",
    "\n",
    "[主动学习推文汇总](https://mp.weixin.qq.com/s/lBXVJi74hjWuKMFwi18amQ)\n",
    "\n",
    "[主动学习目标检测论文](https://arxiv.org/abs/2103.16130)\n",
    "\n",
    "ps.“半监督学习和主动学习异同：\n",
    "\n",
    "它们均从未标记样例中挑选部分价值量高的样例标注后补充到已标记样例集中来提高分类器精度，降低领域专家的工作量，但二者的学习方式不同：半监督学习一般不需要人工参与，是通过具有一定分类精度的基准分类器实现对未标注样例的自动标注；而主动学习有别于半监督学习的特点之一就是需要将挑选出的高价值样例进行人工准确标注。半监督学习通过用计算机进行自动或半自动标注代替人工标注，虽然有效降低了标注代价，但其标注结果依赖于用部分已标注样例训练出的基准分类器的分类精度，因此并不能保证标注结果完全正确。相比而言，主动学习挑选样例后是人工标注，不会引入错误类标”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.“Human-in-the-loop”交互式数据标注框架\n",
    "通过用户已标注的一部分数据来训练 AI 模型，通过此模型来标注剩余数据，从中筛选出 AI 模型标注较为困难的数据进行人工标注，再将这些数据用于模型的优化。几轮过后，用于数据标注的 AI 模型将会具备较高的精度，更好地进行数据标注。\n",
    "[网站地址](https://www.jiqizhixin.com/articles/2020-09-29-6)\n",
    "\n",
    "华为云\n",
    "[相关科普网站](https://developer.huaweicloud.com/hero/forum.php?mod=viewthread&tid=91942)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.用于生物医学图像分析的微调卷积神经网络:主动和增量\n",
    "这篇文章提出的方法主要想解决深度学习应用中的一个重要问题：如何使用尽可能少的标注数据集训练一个模型，这个模型的性能可以达到一个由大量的标注数据集按照普通方法（随机选择训练数据）训练得到的模型的性能。\n",
    "关键词：Active Learning + Transfer Learning、Data Augmentation、Majority Selection、Continuously Fine-Tuning\n",
    "[论文地址](https://openaccess.thecvf.com/content_cvpr_2017/html/Zhou_Fine-Tuning_Convolutional_Neural_CVPR_2017_paper.html)\n",
    "\n",
    "论文作者的[博客](https://www.jianshu.com/p/42801f031cfa)和[个人主页](https://www.zongweiz.com/)\n",
    "\n",
    "[衍生工作地址](https://blog.csdn.net/Houchaoqun_XMU/article/details/80146710)\n",
    "\n",
    "[Learning Active Learning from Data](https://papers.nips.cc/paper/2017/file/8ca8da41fe1ebc8d3ca31dc14f5fc56c-Paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习\n",
    "在迁移学习中，已有的知识叫做源域(source domain)，要学习的新知识叫目标域(target domain)。迁移学习研究如何把源域的知识迁移到目标域上。特别地，在机器学习领域中，迁移学习研究如何将已有模型应用到新的不同的、但是有一定关联的领域中。传统机器学习在应对数据的分布、维度，以及模型的输出变化等任务时，模型不够灵活、结果不够好，而迁移学习放松了这些假设。在数据分布、特征维度以及模型输出变化条件下，有机地利用源域中的知识来对目标域更好地建模。另外，在有标定数据缺乏的情况下，迁移学习可以很好地利用相关领域有标定的数据完成数据的标定。[链接](https://github.com/jindongwang/transferlearning/blob/master/doc/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.借助迁移学习和自动标注，解决AI模型训练中的两大难题\n",
    "深度学习的特点是不需要人工手动找出特征值，系统可以自动从数据里提取特征值。MATLAB里面有很多自动标记的工具和功能。LiDAR三维点云技术可以对每一点进行标注，把这个点聚类在一起聚成一个目标模型，然后再把目标具体代表的实物辨别出来。有些用户已经采用MATLAB的工具进行了开发，著名的汽车配件公司AUTOLIV就在用这种方式进行自动数据标注。\n",
    "\n",
    "以膨化食品智能检测为例，研究人员可以在用户咬食品的时候提取特征，用咬合声音和咬合力度衡量食品的松脆度，有了这两个特征，还需要开发一个机器学习的分类器，而MATLAB提供了分类学习器。开发者通过这个工具不需要一个一个去试各种分类器的算法，使用MATLAB提供的APP去一次性尝试所有算法。开始运行APP后，用户选好数据和需要训练的分类器，然后进行训练。在训练过程中，用户可以看到每个分类器的整体结果，选择精确度最高的一个，然后进行更多的调查和研究。如果用户没有研究过AI，可以用MATLAB提供的APP进行学习，去尝试所有机器学习的算法。[链接](https://cloud.tencent.com/developer/news/227246)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.基于迁移学习与深度卷积特征的图像标注方法研究\n",
    "(1)针对特定应用领域数据集已标注图像样本数量不足的问题,利用相关领域的图像大数据集,提出了基于迁移学习的深度卷积特征学习方法。\n",
    "\n",
    "(2)针对图像数据集中相似度较高的类别之间容易产生样本误分类的问题,基于迁移学习与精细分类的思想,提出了两级层次特征学习的图像分类与标注方法。\n",
    "\n",
    "(3)针对多标签图像全局特征提取困难与表示能力不足的问题,通过修改网络的损失函数,提出了基于深度卷积特征的多标签图像排序方法。\n",
    "\n",
    "(4)针对图像大数据背景下,如何充分利用多源异构图像特征的问题,提出了基于多核学习的多特征融合图像标注方法。\n",
    "\n",
    "[论文链接](https://cdmd.cnki.com.cn/Article/CDMD-10335-1017119555.htm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.零样本迁移学习\n",
    "迁移学习的两种极端形式是一次性学习和零学习，有时也称为零数据学习。在One shot learning中，只有一个被标记的转移任务的例子；而对于zero shot learning学习任务，是想能够在没有获得任何训练数据的情况下解决一个问题。one-shot learning 致力于从一个或少量的图片中学习到目标分类的信息。Fei Fei等人在2006证明 One shot learning 是可能的。\n",
    "[科普链接](https://www.jiqizhixin.com/graph/technologies/d3a2c2a7-0181-4bfe-ac33-540f12116dbf)\n",
    "\n",
    "基于深度模型的零样本迁移学习\n",
    "与传统迁移学习不同,零样本迁移学习的目标是,在标注信息或者数据量为零的条件下,实现将源任务中所学的知识有效迁移到目标任务中。\n",
    "[论文链接](https://cdmd.cnki.com.cn/Article/CDMD-10335-1020738482.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度特征融合\n",
    "在很多工作中，融合不同尺度的特征是提高分割性能的一个重要手段。低层特征分辨率更高，包含更多位置、细节信息，但是由于经过的卷积更少，其语义性更低，噪声更多。高层特征具有更强的语义信息，但是分辨率很低，对细节的感知能力较差。如何将两者高效融合，取其长处，弃之糟泊，是改善分割模型的关键。很多工作通过融合多层来提升检测和分割的性能，按照融合与预测的先后顺序，分类为早融合(Early fusion)和晚融合(Late fusion)。[科普链接](https://blog.csdn.net/xys430381_1/article/details/88370733)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.融合多特征的深度学习标注方法\n",
    "此论文提出一种融合多特征的深度学习图像自动标注方法,将图像视觉特征以不同权重组合成词包,根据输入输出变量优化深度信念网络,完成大规模图像数据语义自动标注。\n",
    "\n",
    "[论文链接](http://www.cqvip.com/qk/91690x/20181/674152241.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 半监督生成对抗网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.基于半监督编码生成对抗网络的图像分类模型\n",
    "为解决在生成对抗网络 (Generative adversarial network, GANs)模型的框架中并没有考虑用于提取图像特征的结构的问题, 此论文文提出一种新的半监督分类模型:在原生成对抗网络模型中添加了一个编码器结构, 用于直接提取图像特征, 并构造了一种新的半监督训练方式, 以进一步利用其模型的学习能力,实验表明获得了突出的分类效果.\n",
    "\n",
    "[论文地址](http://www.aas.net.cn/fileZDHXB/journal/article/zdhxb/2020/3/PDF/zdhxb-46-3-531.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.基于情境条件的生成对抗网络半监督学习\n",
    "基于对抗性损失的绘画图像半监督学习方法：将随机去除斑块的图像交给生成器，生成器的任务是根据周围的像素填充空洞。然后，绘制的图像被呈现给一个鉴别器网络来判断它们是否是真实的(未经修改的训练图像)，这个任务作为一个正则化的标准监督训练的鉴别器。此方法够以半监督的方式直接训练大型vgg式网络。\n",
    "\n",
    "[论文地址](https://openreview.net/pdf?id=BJ--gPcxl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Anno-Mage\n",
    "\n",
    "Anno-Mage是一个半自动标注工具，通过一个通用模型对数据集进行检测。但这个工具能标注的物品类型有限，也没有模型迭代逐步求精的过程，可以自行对其源码进行修改优化。\n",
    "\n",
    "[github代码地址](https://github.com/virajmavani/semi-auto-image-annotation-tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.easyDL智能标注\n",
    "\n",
    "#### 2.1智能标注\n",
    "百度easyDL提供了智能标注的功能，思路如下：先对小批量数据进行标注学习训练，然后以学习结果去标注剩下的数据集，然后人工纠正，迭代求精。\n",
    "\n",
    "[easyDL网址](https://ai.baidu.com/easydl/lite)\n",
    "\n",
    "[智能检测技术文档](https://ai.baidu.com/ai-doc/EASYDL/lk38n327g)\n",
    "#### 2.2数据导出\n",
    "因easyDL官方不提供数据导出功能和api，阻碍了我们把数据拿到Tensorflow和Pytorch进行训练。故可通过爬虫技术来爬取训练好的数据。\n",
    "\n",
    "[工具所在github地址](https://github.com/kooky126/easydl2labelImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.交互式自动标注工具——EISeg\n",
    "针对语义分割与实例分割任务\n",
    "\n",
    "先用预训练模型对图像进行预标注，对于标注不精准、有误差的地方，再通过一系列绿色点（正点）和红色点（负点）对目标对象边缘进行精准的调整，从而实现精细化标注\n",
    "\n",
    "[Github地址](https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.2/contrib/EISeg)\n",
    "\n",
    "[安装方法与使用介绍](https://github.com/PaddleCV-SIG/EISeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、专利\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.专利CN103020261A\n",
    "基于视觉信息和语义标注一致性原则\n",
    "\n",
    "此专利为一种图像自动标注方法，有三个主要步骤：\n",
    "\n",
    "第一步，采用仿射传播聚类算法从个人照片集中选出一些代表性图像来描述该类视觉信息，这样可大大减少训练图像数目；\n",
    "\n",
    "第二步，依据视觉信息和语义标注一致性原则，对代表性图像进行合理标注，这有助于提高图像检索和管理的性能；\n",
    "\n",
    "最后，利用带重新启动的随机游走算法，自动标注其它图像。\n",
    "\n",
    "[专利地址](https://patents.google.com/patent/CN103020261A/zh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.专利CN103942561B\n",
    "基于主动学习的网络图像标注方法\n",
    "\n",
    "该方法：首先基于图像数据集构建表征图像视觉相似性关系的K近邻图结构，计算相应的拉普拉斯图矩阵L；\n",
    "\n",
    "接着采用迭代计算求解最优化问题，选择出T个标注样本让用户进行标注；然后根据选择出来的T个标注样本训练多类别SVM分类器模型fsvm，\n",
    "\n",
    "最后基于训练的SVM分类模型fsvm对图像数据集中的图像进行图像类别判断，依据判别结果对图像进行标注，从而实现基于主动学习的图像标注。\n",
    "\n",
    "本方法采用迭代依次挑选出最具代表性的图像数据进行交互式标注，不仅提高训练的SVM模型性能和图像标注的准确度，还能减少需要标注的图像数目，达到减轻人工劳动量的目的。\n",
    "\n",
    "[专利地址](https://patents.google.com/patent/CN103942561B/zh)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29e304988e468881e77823f4b3a28d7f4a5071d0996e0326fa3cd8c71e2f6730"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}